{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "from shapely.geometry import Point\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, CircleMarker, LayersControl, GeoData, basemaps, Heatmap, LegendControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I chose to create an API object, to include the different sensor systems as separate layers in the map:\n",
    "class Firms_source_object:\n",
    "    ''' FIRMS API Objects\n",
    "    FIRMS (Fire Information for Resource Management System) is NASAs open data platform for wildfire observation.\n",
    "    They provide several sensors with various days.\n",
    "    Source: https://firms.modaps.eosdis.nasa.gov/\n",
    "    '''\n",
    "    def __init__(self, api_token: str, sensor_source: str, day_range = 1, base_url = \"https://firms.modaps.eosdis.nasa.gov/api/area/csv\"):\n",
    "        self.base_url = base_url\n",
    "        self.__api_token = api_token\n",
    "        self.sensor_source = sensor_source\n",
    "        self.day_range = day_range\n",
    "        self.__api = f'{self.base_url}/{self.__api_token}/{self.sensor_source}/world/{self.day_range}' ## creates the original url: \"https://firms.modaps.eosdis.nasa.gov/api/area/csv/36ece617d2f514d4e90f01418d1b9e28/VIIRS_SNPP_NRT/world/1\"\n",
    "\n",
    "\n",
    "    def get_data(self):\n",
    "        '''The API returns a csv file, which can directely be opened with panda'''\n",
    "        self.data = pd.read_csv(self.__api) ## Makes API call\n",
    "        self.api_timestamp = datetime.now() ## Time when API call was made\n",
    "        return self.data\n",
    "\n",
    "\n",
    "    def is_uptodate(self):\n",
    "        if hasattr(self, \"api_timestamp\"):\n",
    "            time_delta = datetime.now() - self.api_timestamp\n",
    "            if time_delta < timedelta(minutes = 15):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Wildfire_layer:\n",
    "    def __init__(self,firms_source: Firms_source_object, layer_name: str, fill_color = \"red\"):\n",
    "        self.firms_source = firms_source\n",
    "        self.data = self.retrieve_data(self.firms_source)\n",
    "        self.layer = GeoData(geo_dataframe = self.data,\n",
    "                            name = layer_name,\n",
    "                            style={'color': \"black\",'fillColor':fill_color, 'opacity':1, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.6, 'radius':8},\n",
    "                            hover_style={'fillColor': 'yellow' , 'fillOpacity': 0.2},\n",
    "                            point_style = {'radius': 3, 'color': 'red', 'fillOpacity': 0.8, 'fillColor': fill_color, 'weight': 3},\n",
    "                            )\n",
    "\n",
    "\n",
    "    def retrieve_data(self, firms_object): ##Firms Object, Call happen with retrieve_data(self.firms_source)\n",
    "        if firms_object.is_uptodate():\n",
    "            if hasattr(self, \"data_clean\"):\n",
    "                return self.data_clean\n",
    "            else: # API Data is Up-to-date, but data_clean is missing -> don't make new API Call, just clean internal data\n",
    "                self.data_clean = self.clean_data(firms_object.data) \n",
    "                return self.data_clean\n",
    "        # If API Data is not Up-to-date: api.get_data()        \n",
    "        data_raw = firms_object.get_data()\n",
    "        self.data_clean = self.clean_data(data_raw)\n",
    "        return self.data_clean\n",
    "\n",
    "\n",
    "    def clean_data(self, data_raw):\n",
    "        data_clean = data_raw\n",
    "        data_clean[\"geometry\"] = [Point(xy) for xy in zip(data_clean['longitude'], data_clean['latitude'])]\n",
    "        data_clean = data_clean.drop([\"latitude\",\"longitude\"],axis = 1)\n",
    "        self.data_clean = gpd.GeoDataFrame(data_clean, crs=\"EPSG:4326\")\n",
    "        return self.data_clean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class WF_overview(Wildfire_layer): ## An Overview Layer, which produced a heatmap based on 4 souces\n",
    "    def __init__(self, source1,source2, source3, source4):\n",
    "        self.s1 = source1\n",
    "        self.s2 = source2\n",
    "        self.s3 = source3\n",
    "        self.s4 = source4\n",
    "        self.__heatmap = self.make_heatmap()\n",
    "        self.layer = self.get_heatmap()\n",
    "\n",
    "\n",
    "    def make_heatmap(self): ## This Funciton here was created by chat-gpt\n",
    "        merged_points = pd.concat([self.retrieve_data(self.s1),\n",
    "                                self.retrieve_data(self.s2),\n",
    "                                self.retrieve_data(self.s3),\n",
    "                                self.retrieve_data(self.s4)], ignore_index=True)\n",
    "        locations = [[point.y, point.x] for point in merged_points.geometry]\n",
    "        heatmap = Heatmap(locations=locations, radius=20, blur=10, name = \"Heatmap\", opacity = 0)\n",
    "        self.timestamp_heatmap = datetime.now()\n",
    "        return heatmap\n",
    "\n",
    "    def get_heatmap(self):\n",
    "        if hasattr(self, \"timestamp_heatmap\"):\n",
    "            if (datetime.now() - self.timestamp_heatmap) < timedelta(minutes = 15):\n",
    "                return self.__heatmap\n",
    "        return self.make_heatmap()\n",
    "\n",
    "\n",
    "\n",
    "class Wildfire_map:\n",
    "    def __init__(self,layer_list):\n",
    "        m = Map(center=(46.78513, 9.07178), zoom = 6,basemap= basemaps.OpenStreetMap.Mapnik, scroll_wheel_zoom=True)\n",
    "        m.add(LayersControl())\n",
    "        legend = {}\n",
    "        for l in layer_list:\n",
    "            m.add(l.layer)\n",
    "            if hasattr(l.layer, \"style\"):\n",
    "                legend[l.layer.name] = l.layer.style[\"fillColor\"]\n",
    "        m.add(LegendControl(legend, position = \"topright\"))\n",
    "        self.m = m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"36ece617d2f514d4e90f01418d1b9e28\" ##This is my private token\n",
    "\n",
    "## Create various FIRMS API Objects, with different sensors:\n",
    "snpp = Firms_source_object(api_token = token, sensor_source= \"VIIRS_SNPP_NRT\")\n",
    "modis = Firms_source_object(token, \"MODIS_NRT\")\n",
    "noaa20 = Firms_source_object(token, \"VIIRS_NOAA20_NRT\")\n",
    "noaa21 = Firms_source_object(token, \"VIIRS_NOAA21_NRT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Wildfire_layer(snpp1, \"VIIRIS SNPP Fires\", \"red\")\n",
    "layer2 = Wildfire_layer(modis, \"MODIS Fires\", \"blue\")\n",
    "#layer3 = Wildfire_layer(noaa20, \"NOAA 20 Fires\", \"green\")\n",
    "#overview = WF_overview(snpp,modis,noaa20,noaa21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1 = Wildfire_map([overview, layer1]).m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = layer1.layer\n",
    "l2 = layer2.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Map(center=(46.78513, 9.07178), zoom = 6, basemap= basemaps.Esri.WorldTopoMap)\n",
    "m2.add(l1)\n",
    "m2.add(l1)\n",
    "control = LayersControl(position = \"topright\", collapse = False)\n",
    "m2.add(control)\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_snpp[\"geometry\"] = [Point(xy) for xy in zip(data_snpp['longitude'], data_snpp['latitude'])]\n",
    "gdf = gpd.GeoDataFrame(data_snpp, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api2 = \"https://services3.arcgis.com/T4QMspbfLg3qTGWY/arcgis/rest/services/IMSR_Incident_Locations_Most_Recent_View/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\"\n",
    "\n",
    "response = requests.get(api2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame.from_features(response.json()['features'],crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snpp1 = Firms_source(api_token = token, sensor_source= \"VIIRS_SNPP_NRT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo876",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
